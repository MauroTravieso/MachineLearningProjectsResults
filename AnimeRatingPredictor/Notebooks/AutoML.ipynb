{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "AutoMLProject01.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StxbZGOO2y3I",
    "colab_type": "text"
   },
   "source": [
    "# Install AutoML"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2BisgUVyh-3x",
    "colab_type": "code",
    "outputId": "64cd6770-6a26-4223-b5c5-c2b512cdc5fd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    }
   },
   "source": [
    "!apt-get install swig -y\n",
    "!pip install Cython numpy\n",
    "\n",
    "!pip install auto-sklearn"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "swig is already the newest version (3.0.12-1).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-410\n",
      "Use 'apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.12)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.4)\n",
      "Requirement already satisfied: auto-sklearn in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.13.2)\n",
      "Requirement already satisfied: smac==0.8 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.8.0)\n",
      "Requirement already satisfied: ConfigSpace<0.5,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.4.10)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (3.13)\n",
      "Requirement already satisfied: pynisher>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.5.0)\n",
      "Requirement already satisfied: pyrfr<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.7.4)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.29.12)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.16.4)\n",
      "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.19.2)\n",
      "Requirement already satisfied: xgboost>=0.80 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.90)\n",
      "Requirement already satisfied: lockfile in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.12.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.24.2)\n",
      "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.7)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (5.4.8)\n",
      "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (2.4.0)\n",
      "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (41.0.1)\n",
      "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (3.7.4)\n",
      "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (0.4.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.12.0)\n",
      "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.8.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (2.4.0)\n",
      "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.2->auto-sklearn) (0.14)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2.5.3)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2018.9)\n",
      "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.2)\n",
      "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.1.3)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.10.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (19.0)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.9.0)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.7.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.21.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (0.7.12)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->smac==0.8->auto-sklearn) (1.1.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2019.6.16)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d-Z7JRDni3Ms",
    "colab_type": "code",
    "outputId": "db86cb41-1804-4c50-bb2d-340a4c04ae03",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    }
   },
   "source": [
    "!pip install auto-sklearn"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: auto-sklearn in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
      "Requirement already satisfied: pynisher>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.5.0)\n",
      "Requirement already satisfied: pyrfr<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.16.4)\n",
      "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.19.2)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.29.12)\n",
      "Requirement already satisfied: lockfile in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.12.2)\n",
      "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.13.2)\n",
      "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (5.4.8)\n",
      "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (2.4.0)\n",
      "Requirement already satisfied: xgboost>=0.80 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.90)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (3.13)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (41.0.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.24.2)\n",
      "Requirement already satisfied: smac==0.8 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.8.0)\n",
      "Requirement already satisfied: ConfigSpace<0.5,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.4.10)\n",
      "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.2->auto-sklearn) (0.14)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2.5.3)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2018.9)\n",
      "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.8.5)\n",
      "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (0.4.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.12.0)\n",
      "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (3.7.4)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (2.4.0)\n",
      "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.1.3)\n",
      "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (19.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (0.7.12)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.10.1)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.2)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.9.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.21.0)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->smac==0.8->auto-sklearn) (1.1.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (3.0.4)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p9UE4j6toFjO",
    "colab_type": "code",
    "outputId": "24093ac6-33d0-4d25-8c91-29fd74351e84",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    }
   },
   "source": [
    "import autosklearn.classification\n"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GjDTVskomp1",
    "colab_type": "text"
   },
   "source": [
    "# AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eWSIgFWo8O2",
    "colab_type": "text"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a59x2kHcpQv7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aXK2-zGSpCxL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#%% md\n",
    "#### MyPCA\n",
    "#%%\n",
    "def myPCA(data,n):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(data)\n",
    "    df = pca.transform(data)\n",
    "    PCA_Data = pd.DataFrame(df)\n",
    "    return PCA_Data\n",
    "\n",
    "#%% md\n",
    "#### myNormalize\n",
    "#%%\n",
    "def myNormalize(data):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    Normalized_Data = min_max_scaler.fit_transform(data)\n",
    "    Normalized_Data = pd.DataFrame(Normalized_Data)\n",
    "    return Normalized_Data\n",
    "\n",
    "#%% md\n",
    "#### myEncode\n",
    "#%%\n",
    "def myEncode(data,col): \n",
    "    NewData_Encode = data.copy()\n",
    "    NewData_Encode = pd.get_dummies(NewData_Encode, columns=col, prefix = col)\n",
    "    return NewData_Encode\n",
    "\n",
    "\n",
    "#%% md\n",
    "#### myCleanAndTransformData\n",
    "#%%\n",
    "def myCleanAndTransformData(data):\n",
    "    \n",
    "    #Drop null rows\n",
    "    NewData = data.dropna()\n",
    "    #Remove unknown ata\n",
    "    NewData = NewData[NewData['episodes']!='Unknown']\n",
    "    #Add a new column rating class \n",
    "    NewData['Class']=1\n",
    "    # 1: High\n",
    "    # or 0: Low based on rating\n",
    "    NewData.loc[NewData['rating'] >= NewData['rating'].mean(), 'Class'] = 1\n",
    "    NewData.loc[NewData['rating'] < NewData['rating'].mean(), 'Class'] = 0\n",
    "    \n",
    "    #Split genre values into rows\n",
    "    NewData = pd.DataFrame(NewData.genre.str.split(',').tolist(), index=[NewData.anime_id,NewData.type,NewData.episodes,NewData.rating,NewData.members,NewData.Class]).stack()\n",
    "    NewData = NewData.reset_index([0,'anime_id','type','episodes','rating','members','Class'])\n",
    "    NewData.columns=['anime_id','type','episodes','rating','members','Class','genre']\n",
    "    \n",
    "    #Encode type feature: 6 unique values\n",
    "    NewData = myEncode(NewData,['type'])\n",
    " \n",
    "    #Encode genre feature: 82 unique values\n",
    "    NewData = myEncode(NewData,['genre'])\n",
    " \n",
    "     #Drop anmie_id,rating,Class\n",
    "    NewData = NewData.drop(['rating'],axis=1)\n",
    "    NewData = NewData.drop(columns=['anime_id'])\n",
    "    #NewData = NewData.drop(columns=['episodes'])  \n",
    "    \n",
    "    return NewData\n",
    "\n",
    "\n",
    "#%% md\n",
    "#### mySplitData\n",
    "#%%\n",
    "def mySplitData(X_Data,Y_Data,test_size,random_state):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_Data, Y_Data, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def mySplitDataByTrainSize(X_Data,Y_Data,train_size,random_state):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_Data, Y_Data, train_size=train_size, random_state=random_state)\n",
    "    X_train, X_test, y_train, y_test = mySplitData(X_train,y_train,0.33,random_state)\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vWwslp1EpaUW",
    "colab_type": "code",
    "outputId": "db87ef0f-d1ab-4e36-96e0-8bcdcc3d44d9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    }
   },
   "source": [
    "#%% md\n",
    "# Load data from files\n",
    "#%%\n",
    "RawData = pd.read_csv('anime.csv')\n",
    "RawData.head()"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>genre</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>rating</th>\n",
       "      <th>members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32281</td>\n",
       "      <td>Kimi no Na wa.</td>\n",
       "      <td>Drama, Romance, School, Supernatural</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>9.37</td>\n",
       "      <td>200630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5114</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n",
       "      <td>TV</td>\n",
       "      <td>64</td>\n",
       "      <td>9.26</td>\n",
       "      <td>793665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28977</td>\n",
       "      <td>Gintama°</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>9.25</td>\n",
       "      <td>114262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9253</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>Sci-Fi, Thriller</td>\n",
       "      <td>TV</td>\n",
       "      <td>24</td>\n",
       "      <td>9.17</td>\n",
       "      <td>673572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9969</td>\n",
       "      <td>Gintama&amp;#039;</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>9.16</td>\n",
       "      <td>151266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                              name  ... rating members\n",
       "0     32281                    Kimi no Na wa.  ...   9.37  200630\n",
       "1      5114  Fullmetal Alchemist: Brotherhood  ...   9.26  793665\n",
       "2     28977                          Gintama°  ...   9.25  114262\n",
       "3      9253                       Steins;Gate  ...   9.17  673572\n",
       "4      9969                     Gintama&#039;  ...   9.16  151266\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FwC0YFqhptN3",
    "colab_type": "code",
    "outputId": "e7142a3f-ac7d-4c7e-e605-adaa9efd8c99",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    }
   },
   "source": [
    "#%% md\n",
    "#### Clean and Transform Data\n",
    "#%%\n",
    "Cleaned_Data = myCleanAndTransformData(RawData)\n",
    "Y_Data = Cleaned_Data['Class']\n",
    "X_Data = Cleaned_Data.drop(columns=['Class'])\n",
    "\n",
    "#%% md\n",
    "#### Normalize  Data\n",
    "#%%\n",
    "Normalized_Data = myNormalize(X_Data)\n",
    "#%% md\n",
    "#### PCA\n",
    "#%%\n",
    "n_components=40\n",
    "PCA_Data = myPCA(Normalized_Data,n_components)\n",
    "PCA_Data.head()"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.311566</td>\n",
       "      <td>0.786508</td>\n",
       "      <td>-0.420821</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>-0.078664</td>\n",
       "      <td>-0.049645</td>\n",
       "      <td>-0.062636</td>\n",
       "      <td>0.007171</td>\n",
       "      <td>-0.075350</td>\n",
       "      <td>-0.030938</td>\n",
       "      <td>0.086265</td>\n",
       "      <td>-0.139423</td>\n",
       "      <td>-0.157023</td>\n",
       "      <td>0.028296</td>\n",
       "      <td>-0.081142</td>\n",
       "      <td>-0.232689</td>\n",
       "      <td>-0.299072</td>\n",
       "      <td>0.804718</td>\n",
       "      <td>-0.258789</td>\n",
       "      <td>-0.007697</td>\n",
       "      <td>-0.094827</td>\n",
       "      <td>-0.108054</td>\n",
       "      <td>-0.062482</td>\n",
       "      <td>0.025710</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>-0.024982</td>\n",
       "      <td>-0.033484</td>\n",
       "      <td>-0.004927</td>\n",
       "      <td>-0.011708</td>\n",
       "      <td>-0.006766</td>\n",
       "      <td>-0.011789</td>\n",
       "      <td>-0.014352</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>-0.010511</td>\n",
       "      <td>-0.008306</td>\n",
       "      <td>-0.003907</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>-0.013950</td>\n",
       "      <td>-0.006672</td>\n",
       "      <td>-0.005472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.284842</td>\n",
       "      <td>0.763991</td>\n",
       "      <td>-0.412009</td>\n",
       "      <td>-0.010872</td>\n",
       "      <td>-0.110067</td>\n",
       "      <td>-0.087028</td>\n",
       "      <td>-0.096769</td>\n",
       "      <td>0.054629</td>\n",
       "      <td>-0.179466</td>\n",
       "      <td>-0.045545</td>\n",
       "      <td>0.764386</td>\n",
       "      <td>0.581467</td>\n",
       "      <td>0.033980</td>\n",
       "      <td>-0.066736</td>\n",
       "      <td>0.030945</td>\n",
       "      <td>0.068189</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>-0.031949</td>\n",
       "      <td>-0.043617</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>-0.027468</td>\n",
       "      <td>-0.040192</td>\n",
       "      <td>-0.033368</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>-0.016136</td>\n",
       "      <td>-0.028665</td>\n",
       "      <td>-0.009426</td>\n",
       "      <td>-0.005297</td>\n",
       "      <td>-0.004070</td>\n",
       "      <td>-0.007261</td>\n",
       "      <td>-0.012869</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>-0.011367</td>\n",
       "      <td>-0.008377</td>\n",
       "      <td>-0.001193</td>\n",
       "      <td>0.008558</td>\n",
       "      <td>-0.013429</td>\n",
       "      <td>-0.008346</td>\n",
       "      <td>-0.006490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284838</td>\n",
       "      <td>0.767910</td>\n",
       "      <td>-0.395570</td>\n",
       "      <td>-0.007614</td>\n",
       "      <td>-0.091869</td>\n",
       "      <td>-0.059765</td>\n",
       "      <td>-0.062085</td>\n",
       "      <td>0.036505</td>\n",
       "      <td>-0.086830</td>\n",
       "      <td>-0.024721</td>\n",
       "      <td>0.092181</td>\n",
       "      <td>-0.282590</td>\n",
       "      <td>-0.451934</td>\n",
       "      <td>-0.569129</td>\n",
       "      <td>0.527433</td>\n",
       "      <td>0.287048</td>\n",
       "      <td>0.035417</td>\n",
       "      <td>-0.060917</td>\n",
       "      <td>-0.105735</td>\n",
       "      <td>-0.014495</td>\n",
       "      <td>-0.031111</td>\n",
       "      <td>-0.062844</td>\n",
       "      <td>-0.045544</td>\n",
       "      <td>0.012576</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>-0.021739</td>\n",
       "      <td>-0.033688</td>\n",
       "      <td>-0.011360</td>\n",
       "      <td>-0.009060</td>\n",
       "      <td>-0.006153</td>\n",
       "      <td>-0.009504</td>\n",
       "      <td>-0.014576</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>-0.012743</td>\n",
       "      <td>-0.010005</td>\n",
       "      <td>-0.005156</td>\n",
       "      <td>0.006695</td>\n",
       "      <td>-0.015398</td>\n",
       "      <td>-0.012940</td>\n",
       "      <td>-0.006419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.291600</td>\n",
       "      <td>0.777175</td>\n",
       "      <td>-0.408316</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>-0.080828</td>\n",
       "      <td>-0.049799</td>\n",
       "      <td>-0.056889</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>-0.070776</td>\n",
       "      <td>-0.027970</td>\n",
       "      <td>0.078032</td>\n",
       "      <td>-0.143404</td>\n",
       "      <td>-0.122693</td>\n",
       "      <td>-0.013062</td>\n",
       "      <td>-0.109523</td>\n",
       "      <td>-0.389584</td>\n",
       "      <td>-0.602805</td>\n",
       "      <td>-0.563640</td>\n",
       "      <td>-0.290750</td>\n",
       "      <td>-0.050590</td>\n",
       "      <td>-0.053017</td>\n",
       "      <td>-0.099432</td>\n",
       "      <td>-0.061860</td>\n",
       "      <td>0.024380</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>-0.027267</td>\n",
       "      <td>-0.035573</td>\n",
       "      <td>-0.010745</td>\n",
       "      <td>-0.013576</td>\n",
       "      <td>-0.007682</td>\n",
       "      <td>-0.012282</td>\n",
       "      <td>-0.015279</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>-0.011312</td>\n",
       "      <td>-0.009465</td>\n",
       "      <td>-0.007631</td>\n",
       "      <td>0.004434</td>\n",
       "      <td>-0.014988</td>\n",
       "      <td>-0.011909</td>\n",
       "      <td>-0.008382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.732145</td>\n",
       "      <td>-0.153155</td>\n",
       "      <td>-0.102203</td>\n",
       "      <td>-0.458230</td>\n",
       "      <td>0.816867</td>\n",
       "      <td>0.046174</td>\n",
       "      <td>0.015773</td>\n",
       "      <td>-0.064781</td>\n",
       "      <td>0.014353</td>\n",
       "      <td>-0.005003</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.017521</td>\n",
       "      <td>-0.007153</td>\n",
       "      <td>0.008121</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>-0.003247</td>\n",
       "      <td>-0.012143</td>\n",
       "      <td>-0.006512</td>\n",
       "      <td>-0.013977</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>-0.027934</td>\n",
       "      <td>-0.018705</td>\n",
       "      <td>-0.009793</td>\n",
       "      <td>-0.001093</td>\n",
       "      <td>0.018532</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>-0.017978</td>\n",
       "      <td>0.010262</td>\n",
       "      <td>0.021732</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>-0.012701</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>-0.014668</td>\n",
       "      <td>-0.007358</td>\n",
       "      <td>0.027884</td>\n",
       "      <td>0.026121</td>\n",
       "      <td>-0.021419</td>\n",
       "      <td>-0.000735</td>\n",
       "      <td>0.056595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2   ...        37        38        39\n",
       "0 -0.311566  0.786508 -0.420821  ... -0.013950 -0.006672 -0.005472\n",
       "1 -0.284842  0.763991 -0.412009  ... -0.013429 -0.008346 -0.006490\n",
       "2 -0.284838  0.767910 -0.395570  ... -0.015398 -0.012940 -0.006419\n",
       "3 -0.291600  0.777175 -0.408316  ... -0.014988 -0.011909 -0.008382\n",
       "4  0.732145 -0.153155 -0.102203  ... -0.021419 -0.000735  0.056595\n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1T50hJ8mq2AZ",
    "colab_type": "code",
    "outputId": "99243798-8b97-464a-d400-44a2afdb520c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    }
   },
   "source": [
    "#%% md\n",
    "####----------------------------------------------------------------\n",
    "#### Split  PCA_Data\n",
    "####----------------------------------------------------------------\n",
    "#%%\n",
    "PCA_X_train, PCA_X_test, PCA_y_train, PCA_y_test  = mySplitData(PCA_Data,Y_Data,0.33,42)\n",
    "\n",
    "PCA_X_train.head()\n",
    "#%%\n",
    "PCA_X_test.head()\n",
    "#%%\n",
    "PCA_y_train.head()\n",
    "#%%\n",
    "PCA_y_test.head()"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22373    0\n",
       "10508    1\n",
       "11570    1\n",
       "22262    0\n",
       "734      1\n",
       "Name: Class, dtype: int64"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uesuJDbrHRU",
    "colab_type": "text"
   },
   "source": [
    "## **Train and Test Model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2Nn4NvY4rM6D",
    "colab_type": "code",
    "outputId": "49f99cbc-bff3-4858-9c14-e8bb5847e3fc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    }
   },
   "source": [
    "# configure auto-sklearn\n",
    "anmie_automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "          time_left_for_this_task=120, # run auto-sklearn for at most 2min\n",
    "          per_run_time_limit=30, # spend at most 30 sec for each model training\n",
    "          include_preprocessors=[\"no_preprocessing\"],\n",
    "          )\n",
    "\n",
    "# train model(s)\n",
    "anmie_automl.fit(PCA_X_train, PCA_y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "PCA_y_predicted = anmie_automl.predict(PCA_X_test)\n",
    "test_acc = accuracy_score(PCA_y_test, PCA_y_predicted)\n",
    "\n",
    "print(\"Test Accuracy score {0}\".format(test_acc))"
   ],
   "execution_count": 47,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "[WARNING] [2019-07-31 16:40:50,472:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-31 16:40:50,483:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-31 16:40:52,490:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-31 16:40:54,495:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-31 16:40:56,507:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-31 16:40:58,517:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "1\n",
      "['/tmp/autosklearn_tmp_137_7300/.auto-sklearn/ensembles/1.0000000000.ensemble', '/tmp/autosklearn_tmp_137_7300/.auto-sklearn/ensembles/1.0000000001.ensemble', '/tmp/autosklearn_tmp_137_7300/.auto-sklearn/ensembles/1.0000000002.ensemble', '/tmp/autosklearn_tmp_137_7300/.auto-sklearn/ensembles/1.0000000003.ensemble', '/tmp/autosklearn_tmp_137_7300/.auto-sklearn/ensembles/1.0000000004.ensemble']\n",
      "Test Accuracy score 0.804424550228114\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEjZqYPpswxw",
    "colab_type": "text"
   },
   "source": [
    "## Inspecting the results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "loIqJX6_iI02",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "46af6d55-2bda-4b8b-b148-e39daf5092cd"
   },
   "source": [
    "# evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "PCA_y_predicted = anmie_automl.predict(PCA_X_test)\n",
    "test_acc = accuracy_score(PCA_y_test, PCA_y_predicted)\n",
    "\n",
    "print(\"Test Accuracy score {0}\".format(test_acc))"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Test Accuracy score 0.804424550228114\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "47ATUCSls-cx",
    "colab_type": "code",
    "outputId": "273b57a4-515d-4bef-9d72-2d3efc29d4e2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    }
   },
   "source": [
    "anmie_automl.sprint_statistics()"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'auto-sklearn results:\\n  Dataset name: 64b53ca9ba24ac1e45ad29eb0951a812\\n  Metric: accuracy\\n  Best validation score: 0.796608\\n  Number of target algorithm runs: 7\\n  Number of successful target algorithm runs: 5\\n  Number of crashed target algorithm runs: 0\\n  Number of target algorithms that exceeded the time limit: 2\\n  Number of target algorithms that exceeded the memory limit: 0\\n'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 30
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VW2h1ROVtCWT",
    "colab_type": "code",
    "outputId": "fef63a9f-fac8-4b9c-f440-1bb6ac0a7b35",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    }
   },
   "source": [
    "anmie_automl.show_models()"
   ],
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"[(0.820000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'normalize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5240592829918601, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 10, 'classifier:random_forest:min_samples_split': 16, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.00012586572428922356},\\ndataset_properties={\\n  'task': 1,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'classification',\\n  'signed': False})),\\n(0.120000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'gradient_boosting', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:gradient_boosting:criterion': 'mse', 'classifier:gradient_boosting:learning_rate': 0.051832615669195795, 'classifier:gradient_boosting:loss': 'deviance', 'classifier:gradient_boosting:max_depth': 6, 'classifier:gradient_boosting:max_features': 0.8807456180216267, 'classifier:gradient_boosting:max_leaf_nodes': 'None', 'classifier:gradient_boosting:min_impurity_decrease': 0.0, 'classifier:gradient_boosting:min_samples_leaf': 7, 'classifier:gradient_boosting:min_samples_split': 19, 'classifier:gradient_boosting:min_weight_fraction_leaf': 0.0, 'classifier:gradient_boosting:n_estimators': 366, 'classifier:gradient_boosting:subsample': 0.7314831276137047, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.010000000000000004},\\ndataset_properties={\\n  'task': 1,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'classification',\\n  'signed': False})),\\n(0.060000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5686453602598863, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.41094614430753584},\\ndataset_properties={\\n  'task': 1,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'classification',\\n  'signed': False})),\\n]\""
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 31
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CVYIHHlotGEB",
    "colab_type": "code",
    "outputId": "59efabca-62ad-430d-a359-1eda2369bd8e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "anmie_automl.cv_results_"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 9.36614823,  7.68715644, 30.03748894, 11.33386064,  0.49103284,\n",
       "        29.3589673 , 18.02530432]),\n",
       " 'mean_test_score': array([0.75960427, 0.79660799, 0.        , 0.75767699, 0.6563022 ,\n",
       "        0.78350251, 0.        ]),\n",
       " 'param_balancing:strategy': masked_array(data=['none', 'none', 'none', 'weighting', 'weighting',\n",
       "                    'weighting', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U9'),\n",
       " 'param_categorical_encoding:__choice__': masked_array(data=['one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding'],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U16'),\n",
       " 'param_categorical_encoding:one_hot_encoding:minimum_fraction': masked_array(data=[0.01, 0.00012586572428922356, --, 0.41094614430753584,\n",
       "                    0.00034835629696198427, 0.010000000000000004, --],\n",
       "              mask=[False, False,  True, False, False, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_categorical_encoding:one_hot_encoding:use_minimum_fraction': masked_array(data=['True', 'True', 'False', 'True', 'True', 'True',\n",
       "                    'False'],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U5'),\n",
       " 'param_classifier:__choice__': masked_array(data=['random_forest', 'random_forest', 'libsvm_svc',\n",
       "                    'random_forest', 'gaussian_nb', 'gradient_boosting',\n",
       "                    'random_forest'],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U17'),\n",
       " 'param_classifier:adaboost:algorithm': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:adaboost:learning_rate': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:adaboost:max_depth': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:adaboost:n_estimators': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:bernoulli_nb:alpha': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:bernoulli_nb:fit_prior': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:decision_tree:criterion': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:decision_tree:max_depth_factor': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:decision_tree:max_features': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:decision_tree:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:decision_tree:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:decision_tree:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:decision_tree:min_samples_split': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:decision_tree:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:extra_trees:bootstrap': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:extra_trees:criterion': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:extra_trees:max_depth': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:extra_trees:max_features': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:extra_trees:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:extra_trees:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:extra_trees:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:extra_trees:min_samples_split': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:extra_trees:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:extra_trees:n_estimators': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:gradient_boosting:criterion': masked_array(data=[--, --, --, --, --, 'mse', --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_classifier:gradient_boosting:learning_rate': masked_array(data=[--, --, --, --, --, 0.051832615669195795, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:gradient_boosting:loss': masked_array(data=[--, --, --, --, --, 'deviance', --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_classifier:gradient_boosting:max_depth': masked_array(data=[--, --, --, --, --, 6.0, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:gradient_boosting:max_features': masked_array(data=[--, --, --, --, --, 0.8807456180216267, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:gradient_boosting:max_leaf_nodes': masked_array(data=[--, --, --, --, --, 'None', --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_classifier:gradient_boosting:min_impurity_decrease': masked_array(data=[--, --, --, --, --, 0.0, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:gradient_boosting:min_samples_leaf': masked_array(data=[--, --, --, --, --, 7.0, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:gradient_boosting:min_samples_split': masked_array(data=[--, --, --, --, --, 19.0, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:gradient_boosting:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, 0.0, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:gradient_boosting:n_estimators': masked_array(data=[--, --, --, --, --, 366.0, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:gradient_boosting:subsample': masked_array(data=[--, --, --, --, --, 0.7314831276137047, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:k_nearest_neighbors:n_neighbors': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:k_nearest_neighbors:p': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:k_nearest_neighbors:weights': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:lda:n_components': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:lda:shrinkage': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:lda:shrinkage_factor': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:lda:tol': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:liblinear_svc:C': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:liblinear_svc:dual': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:liblinear_svc:fit_intercept': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:liblinear_svc:intercept_scaling': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:liblinear_svc:loss': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:liblinear_svc:multi_class': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:liblinear_svc:penalty': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:liblinear_svc:tol': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:libsvm_svc:C': masked_array(data=[--, --, 6.342897164595882, --, --, --, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:libsvm_svc:coef0': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:libsvm_svc:degree': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:libsvm_svc:gamma': masked_array(data=[--, --, 0.2229870623330047, --, --, --, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:libsvm_svc:kernel': masked_array(data=[--, --, 'rbf', --, --, --, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_classifier:libsvm_svc:max_iter': masked_array(data=[--, --, -1.0, --, --, --, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:libsvm_svc:shrinking': masked_array(data=[--, --, 'False', --, --, --, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_classifier:libsvm_svc:tol': masked_array(data=[--, --, 2.006345264381097e-05, --, --, --, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:multinomial_nb:alpha': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:multinomial_nb:fit_prior': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:passive_aggressive:C': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:passive_aggressive:average': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:passive_aggressive:fit_intercept': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:passive_aggressive:loss': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:passive_aggressive:tol': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:qda:reg_param': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:random_forest:bootstrap': masked_array(data=['True', 'True', --, 'True', --, --, 'True'],\n",
       "              mask=[False, False,  True, False,  True,  True, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U4'),\n",
       " 'param_classifier:random_forest:criterion': masked_array(data=['gini', 'gini', --, 'gini', --, --, 'gini'],\n",
       "              mask=[False, False,  True, False,  True,  True, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U4'),\n",
       " 'param_classifier:random_forest:max_depth': masked_array(data=['None', 'None', --, 'None', --, --, 'None'],\n",
       "              mask=[False, False,  True, False,  True,  True, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U4'),\n",
       " 'param_classifier:random_forest:max_features': masked_array(data=[0.5, 0.5240592829918601, --, 0.5686453602598863, --,\n",
       "                    --, 0.9260795160807372],\n",
       "              mask=[False, False,  True, False,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:random_forest:max_leaf_nodes': masked_array(data=['None', 'None', --, 'None', --, --, 'None'],\n",
       "              mask=[False, False,  True, False,  True,  True, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U4'),\n",
       " 'param_classifier:random_forest:min_impurity_decrease': masked_array(data=[0.0, 0.0, --, 0.0, --, --, 0.0],\n",
       "              mask=[False, False,  True, False,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:random_forest:min_samples_leaf': masked_array(data=[1.0, 10.0, --, 1.0, --, --, 17.0],\n",
       "              mask=[False, False,  True, False,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:random_forest:min_samples_split': masked_array(data=[2.0, 16.0, --, 2.0, --, --, 7.0],\n",
       "              mask=[False, False,  True, False,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:random_forest:min_weight_fraction_leaf': masked_array(data=[0.0, 0.0, --, 0.0, --, --, 0.0],\n",
       "              mask=[False, False,  True, False,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:random_forest:n_estimators': masked_array(data=[100.0, 100.0, --, 100.0, --, --, 100.0],\n",
       "              mask=[False, False,  True, False,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_classifier:sgd:alpha': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:sgd:average': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:sgd:epsilon': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:sgd:eta0': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:sgd:fit_intercept': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:sgd:l1_ratio': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:sgd:learning_rate': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:sgd:loss': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:sgd:penalty': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:sgd:power_t': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:sgd:tol': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:base_score': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:booster': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:colsample_bylevel': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:colsample_bytree': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:gamma': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:learning_rate': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:max_delta_step': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:max_depth': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:min_child_weight': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:n_estimators': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:normalize_type': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:rate_drop': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:reg_alpha': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:reg_lambda': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:sample_type': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:scale_pos_weight': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_classifier:xgradient_boosting:subsample': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_imputation:strategy': masked_array(data=['mean', 'mean', 'most_frequent', 'most_frequent',\n",
       "                    'mean', 'mean', 'mean'],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U13'),\n",
       " 'param_preprocessor:__choice__': masked_array(data=['no_preprocessing', 'no_preprocessing',\n",
       "                    'no_preprocessing', 'no_preprocessing',\n",
       "                    'no_preprocessing', 'no_preprocessing',\n",
       "                    'no_preprocessing'],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U16'),\n",
       " 'param_rescaling:__choice__': masked_array(data=['standardize', 'normalize', 'standardize',\n",
       "                    'standardize', 'robust_scaler', 'standardize',\n",
       "                    'minmax'],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U13'),\n",
       " 'param_rescaling:quantile_transformer:n_quantiles': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_rescaling:quantile_transformer:output_distribution': masked_array(data=[--, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_rescaling:robust_scaler:q_max': masked_array(data=[--, --, --, --, 0.8245132980938538, --, --],\n",
       "              mask=[ True,  True,  True,  True, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_rescaling:robust_scaler:q_min': masked_array(data=[--, --, --, --, 0.08947420373097192, --, --],\n",
       "              mask=[ True,  True,  True,  True, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'params': [{'balancing:strategy': 'none',\n",
       "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.01,\n",
       "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
       "   'classifier:__choice__': 'random_forest',\n",
       "   'classifier:random_forest:bootstrap': 'True',\n",
       "   'classifier:random_forest:criterion': 'gini',\n",
       "   'classifier:random_forest:max_depth': 'None',\n",
       "   'classifier:random_forest:max_features': 0.5,\n",
       "   'classifier:random_forest:max_leaf_nodes': 'None',\n",
       "   'classifier:random_forest:min_impurity_decrease': 0.0,\n",
       "   'classifier:random_forest:min_samples_leaf': 1,\n",
       "   'classifier:random_forest:min_samples_split': 2,\n",
       "   'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'classifier:random_forest:n_estimators': 100,\n",
       "   'imputation:strategy': 'mean',\n",
       "   'preprocessor:__choice__': 'no_preprocessing',\n",
       "   'rescaling:__choice__': 'standardize'},\n",
       "  {'balancing:strategy': 'none',\n",
       "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.00012586572428922356,\n",
       "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
       "   'classifier:__choice__': 'random_forest',\n",
       "   'classifier:random_forest:bootstrap': 'True',\n",
       "   'classifier:random_forest:criterion': 'gini',\n",
       "   'classifier:random_forest:max_depth': 'None',\n",
       "   'classifier:random_forest:max_features': 0.5240592829918601,\n",
       "   'classifier:random_forest:max_leaf_nodes': 'None',\n",
       "   'classifier:random_forest:min_impurity_decrease': 0.0,\n",
       "   'classifier:random_forest:min_samples_leaf': 10,\n",
       "   'classifier:random_forest:min_samples_split': 16,\n",
       "   'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'classifier:random_forest:n_estimators': 100,\n",
       "   'imputation:strategy': 'mean',\n",
       "   'preprocessor:__choice__': 'no_preprocessing',\n",
       "   'rescaling:__choice__': 'normalize'},\n",
       "  {'balancing:strategy': 'none',\n",
       "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False',\n",
       "   'classifier:__choice__': 'libsvm_svc',\n",
       "   'classifier:libsvm_svc:C': 6.342897164595882,\n",
       "   'classifier:libsvm_svc:gamma': 0.2229870623330047,\n",
       "   'classifier:libsvm_svc:kernel': 'rbf',\n",
       "   'classifier:libsvm_svc:max_iter': -1,\n",
       "   'classifier:libsvm_svc:shrinking': 'False',\n",
       "   'classifier:libsvm_svc:tol': 2.006345264381097e-05,\n",
       "   'imputation:strategy': 'most_frequent',\n",
       "   'preprocessor:__choice__': 'no_preprocessing',\n",
       "   'rescaling:__choice__': 'standardize'},\n",
       "  {'balancing:strategy': 'weighting',\n",
       "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.41094614430753584,\n",
       "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
       "   'classifier:__choice__': 'random_forest',\n",
       "   'classifier:random_forest:bootstrap': 'True',\n",
       "   'classifier:random_forest:criterion': 'gini',\n",
       "   'classifier:random_forest:max_depth': 'None',\n",
       "   'classifier:random_forest:max_features': 0.5686453602598863,\n",
       "   'classifier:random_forest:max_leaf_nodes': 'None',\n",
       "   'classifier:random_forest:min_impurity_decrease': 0.0,\n",
       "   'classifier:random_forest:min_samples_leaf': 1,\n",
       "   'classifier:random_forest:min_samples_split': 2,\n",
       "   'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'classifier:random_forest:n_estimators': 100,\n",
       "   'imputation:strategy': 'most_frequent',\n",
       "   'preprocessor:__choice__': 'no_preprocessing',\n",
       "   'rescaling:__choice__': 'standardize'},\n",
       "  {'balancing:strategy': 'weighting',\n",
       "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.00034835629696198427,\n",
       "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
       "   'classifier:__choice__': 'gaussian_nb',\n",
       "   'imputation:strategy': 'mean',\n",
       "   'preprocessor:__choice__': 'no_preprocessing',\n",
       "   'rescaling:__choice__': 'robust_scaler',\n",
       "   'rescaling:robust_scaler:q_max': 0.8245132980938538,\n",
       "   'rescaling:robust_scaler:q_min': 0.08947420373097192},\n",
       "  {'balancing:strategy': 'weighting',\n",
       "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.010000000000000004,\n",
       "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
       "   'classifier:__choice__': 'gradient_boosting',\n",
       "   'classifier:gradient_boosting:criterion': 'mse',\n",
       "   'classifier:gradient_boosting:learning_rate': 0.051832615669195795,\n",
       "   'classifier:gradient_boosting:loss': 'deviance',\n",
       "   'classifier:gradient_boosting:max_depth': 6,\n",
       "   'classifier:gradient_boosting:max_features': 0.8807456180216267,\n",
       "   'classifier:gradient_boosting:max_leaf_nodes': 'None',\n",
       "   'classifier:gradient_boosting:min_impurity_decrease': 0.0,\n",
       "   'classifier:gradient_boosting:min_samples_leaf': 7,\n",
       "   'classifier:gradient_boosting:min_samples_split': 19,\n",
       "   'classifier:gradient_boosting:min_weight_fraction_leaf': 0.0,\n",
       "   'classifier:gradient_boosting:n_estimators': 366,\n",
       "   'classifier:gradient_boosting:subsample': 0.7314831276137047,\n",
       "   'imputation:strategy': 'mean',\n",
       "   'preprocessor:__choice__': 'no_preprocessing',\n",
       "   'rescaling:__choice__': 'standardize'},\n",
       "  {'balancing:strategy': 'none',\n",
       "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False',\n",
       "   'classifier:__choice__': 'random_forest',\n",
       "   'classifier:random_forest:bootstrap': 'True',\n",
       "   'classifier:random_forest:criterion': 'gini',\n",
       "   'classifier:random_forest:max_depth': 'None',\n",
       "   'classifier:random_forest:max_features': 0.9260795160807372,\n",
       "   'classifier:random_forest:max_leaf_nodes': 'None',\n",
       "   'classifier:random_forest:min_impurity_decrease': 0.0,\n",
       "   'classifier:random_forest:min_samples_leaf': 17,\n",
       "   'classifier:random_forest:min_samples_split': 7,\n",
       "   'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'classifier:random_forest:n_estimators': 100,\n",
       "   'imputation:strategy': 'mean',\n",
       "   'preprocessor:__choice__': 'no_preprocessing',\n",
       "   'rescaling:__choice__': 'minmax'}],\n",
       " 'rank_test_scores': array([3, 1, 6, 4, 5, 2, 6]),\n",
       " 'status': ['Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout']}"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 32
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HhpbbHnV3b3g",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0nlmBEQR6Nd",
    "colab_type": "text"
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FuHZbULXSTfD",
    "colab_type": "code",
    "outputId": "5b03a309-3854-4f5d-a9fd-f5fbd54d02d9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "# train model(s)\n",
    "knn_m = knn.fit(PCA_X_train, PCA_y_train)\n",
    "\n",
    "# evaluate\n",
    "knn_test_acc = knn_m.score(PCA_X_test,PCA_y_test)\n",
    "print(\"Test Accuracy score {0}\".format(knn_test_acc))"
   ],
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Test Accuracy score 0.797279848497891\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZcFpZiIR87D",
    "colab_type": "text"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-HJiVRVCXvKN",
    "colab_type": "code",
    "outputId": "80e16914-6e4a-4ca2-a71d-161b1b72a3d8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "# Create a svm Classifier with PCA data\n",
    "svc = svm.SVC(C=1.0, gamma=0.1, kernel='rbf') # Linear Kernel\n",
    "\n",
    "# train model(s)\n",
    "svm_m = svc.fit(PCA_X_train, PCA_y_train)\n",
    "\n",
    "# evaluate\n",
    "svm_test_acc = svm_m.score(PCA_X_test,PCA_y_test)\n",
    "print(\"Test Accuracy score {0}\".format(svm_test_acc))"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Test Accuracy score 0.6980287509684083\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WefgYsW4R_td",
    "colab_type": "text"
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YmpigibbYm2Q",
    "colab_type": "code",
    "outputId": "13660a2a-0de9-401e-a881-2505e3b4876f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "#Import svm model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Create a DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=0,max_depth=30,min_samples_leaf=20)\n",
    "\n",
    "\n",
    "# train model(s)\n",
    "dt_m = dt.fit(PCA_X_train, PCA_y_train)\n",
    "\n",
    "# evaluate\n",
    "dt_test_acc = dt_m.score(PCA_X_test,PCA_y_test)\n",
    "print(\"Test Accuracy score {0}\".format(dt_test_acc))\n"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Test Accuracy score 0.7936644572609107\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zntQsupZSB_O",
    "colab_type": "text"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4N_gyiFQaL-7",
    "colab_type": "code",
    "outputId": "708e6835-4161-4ca2-f13d-d948f8a2c7f0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "#Import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Random Forest Classifier with original data\n",
    "rf = RandomForestClassifier(criterion ='gini', max_depth= 15, max_features= 'sqrt', min_samples_leaf=1, min_samples_split= 5, n_estimators= 300)\n",
    "\n",
    "\n",
    "# train model(s)\n",
    "rf_m = rf.fit(PCA_X_train, PCA_y_train)\n",
    "\n",
    "# evaluate\n",
    "rf_test_acc = rf_m.score(PCA_X_test,PCA_y_test)\n",
    "print(\"Test Accuracy score {0}\".format(rf_test_acc))\n"
   ],
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Test Accuracy score 0.8053714384092279\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eToqzWdTSFFB",
    "colab_type": "text"
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CkdWo0y0h5PZ",
    "colab_type": "code",
    "outputId": "aade3891-8afe-4cbc-bffc-061e444ed5a5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "#Import svm model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a NN Classifier with PCA data\n",
    "nn = MLPClassifier(max_iter=500)\n",
    "\n",
    "# train model(s)\n",
    "nn_m = nn.fit(PCA_X_train, PCA_y_train)\n",
    "\n",
    "# evaluate\n",
    "nn_test_acc = nn_m.score(PCA_X_test,PCA_y_test)\n",
    "print(\"Test Accuracy score {0}\".format(nn_test_acc))\n"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Test Accuracy score 0.7021606266678144\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z8eT3iobBY8",
    "colab_type": "text"
   },
   "source": [
    "# Comparison between all classifiers (including AutoML)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kyllWO0npzLj",
    "colab_type": "code",
    "outputId": "e3233c82-0231-48bb-e65e-6fd7835d1e8e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    }
   },
   "source": [
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import autosklearn.classification\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "def roc_auc_curve(model,X_train,Y_train,X_test,Y_test):\n",
    "  model.fit(X_train, Y_train)\n",
    "\n",
    "  dt_lm = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "  dt_lm.fit(X_test, Y_test)\n",
    "\n",
    "  y_pred_dt = model.predict_proba(X_test)[:, 1]\n",
    "  fpr_dt, tpr_dt, _ = roc_curve(Y_test, y_pred_dt)\n",
    "  roc_auc = auc(fpr_dt, tpr_dt)\n",
    "  \n",
    "  test_acc_score = model.score(X_test,Y_test)\n",
    "  \n",
    "  return fpr_dt, tpr_dt,roc_auc,test_acc_score\n",
    "\n",
    "# Create a DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0,max_depth=30,min_samples_leaf=20)\n",
    "fpr_dt, tpr_dt,roc_auc,dt_test_acc_score = roc_auc_curve(clf,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
    "\n",
    "\n",
    "#KNN \n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn_fpr, knn_tpr,knn_roc_auc,knn_test_acc_score = roc_auc_curve(knn,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
    "\n",
    "#Random Forest \n",
    "rf = RandomForestClassifier(criterion ='gini', max_depth= 15, max_features= 'sqrt', min_samples_leaf=1, min_samples_split= 5, n_estimators= 300)\n",
    "rf_fpr, rf_tpr,rf_roc_auc,rf_test_acc_score = roc_auc_curve(rf,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
    "\n",
    "#svm \n",
    "svmModel = svm.SVC(C=1.0, gamma=0.1, kernel='rbf',probability=True) # Linear Kernel\n",
    "svm_fpr, svm_tpr,svm_roc_auc,svm_test_acc_score = roc_auc_curve(svmModel,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
    "\n",
    "#NN \n",
    "nn = MLPClassifier(alpha= 0.05, hidden_layer_sizes =(50, 100, 50),max_iter=500)\n",
    "nn_fpr, nn_tpr,nn_roc_auc,nn_test_acc_score = roc_auc_curve(nn,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
    "\n",
    "#AutoML \n",
    "AutoML = autosklearn.classification.AutoSklearnClassifier(\n",
    "          time_left_for_this_task=120, # run auto-sklearn for at most 2min\n",
    "          per_run_time_limit=30, # spend at most 30 sec for each model training\n",
    "          include_preprocessors=[\"no_preprocessing\"]\n",
    "          )\n",
    "AutoML_fpr, AutoML_tpr,AutoML_roc_auc,AutoML_test_acc_score = roc_auc_curve(AutoML,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "\n",
    "plt.plot(fpr_dt, tpr_dt, label='ROC of DT (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot(knn_fpr, knn_tpr, label='ROC of KNN (AUC = %0.2f)' % knn_roc_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, label='ROC of RF (AUC = %0.2f)' % rf_roc_auc)\n",
    "plt.plot(svm_fpr, svm_tpr, label='ROC of SVM (AUC = %0.2f)' % svm_roc_auc)\n",
    "plt.plot(nn_fpr, nn_tpr, label='ROC of NN (AUC = %0.2f)' % nn_roc_auc)\n",
    "plt.plot(AutoML_fpr, AutoML_tpr, label='ROC of AutoML (AUC = %0.2f)' % AutoML_roc_auc)\n",
    "\n",
    "\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "execution_count": 44,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "[WARNING] [2019-07-31 15:57:54,019:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-31 15:57:54,031:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-31 15:57:56,035:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-31 15:57:58,040:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-31 15:58:00,051:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-31 15:58:02,063:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "1\n",
      "['/tmp/autosklearn_tmp_137_3027/.auto-sklearn/ensembles/1.0000000000.ensemble', '/tmp/autosklearn_tmp_137_3027/.auto-sklearn/ensembles/1.0000000001.ensemble', '/tmp/autosklearn_tmp_137_3027/.auto-sklearn/ensembles/1.0000000002.ensemble', '/tmp/autosklearn_tmp_137_3027/.auto-sklearn/ensembles/1.0000000003.ensemble', '/tmp/autosklearn_tmp_137_3027/.auto-sklearn/ensembles/1.0000000004.ensemble']\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N09fx2BdRJh8",
    "colab_type": "text"
   },
   "source": [
    "# Testing Accuracy Scores of all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8bwAazSqRI1P",
    "colab_type": "code",
    "outputId": "b24310cb-113f-49b5-ca17-d7d224f307b3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    }
   },
   "source": [
    "scores = pd.DataFrame({\"score\":[dt_test_acc_score,\n",
    "                       knn_test_acc_score,\n",
    "                       rf_test_acc_score,\n",
    "                       svm_test_acc_score,\n",
    "                       nn_test_acc_score,\n",
    "                       AutoML_test_acc_score],\n",
    "                     \"name\":[\"dt_test_acc_score\",\n",
    "                       \"knn_test_acc_score\",\n",
    "                       \"rf_test_acc_score\",\n",
    "                       \"svm_test_acc_score\",\n",
    "                       \"nn_test_acc_score\",\n",
    "                       \"AutoML_test_acc_score\"]})\n",
    "scores.sort_values(by=['score'])\n",
    "scores"
   ],
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.793664</td>\n",
       "      <td>dt_test_acc_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.797280</td>\n",
       "      <td>knn_test_acc_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.805371</td>\n",
       "      <td>rf_test_acc_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698029</td>\n",
       "      <td>svm_test_acc_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.705001</td>\n",
       "      <td>nn_test_acc_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.804425</td>\n",
       "      <td>AutoML_test_acc_score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                   name\n",
       "0  0.793664      dt_test_acc_score\n",
       "1  0.797280     knn_test_acc_score\n",
       "2  0.805371      rf_test_acc_score\n",
       "3  0.698029     svm_test_acc_score\n",
       "4  0.705001      nn_test_acc_score\n",
       "5  0.804425  AutoML_test_acc_score"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 45
    }
   ]
  }
 ]
}